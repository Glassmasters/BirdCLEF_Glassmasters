{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# import necessary libs\n",
    "import os\n",
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_BASE_FILE_PATH = r\"D:\\Datasets\\birdclef-2023\"\n",
    "TRAIN_SET_FILE_DIR = r\"\\train_audio\"\n",
    "TEST_SET_FILE_DIR = r\"\\test_soundscapes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eBird_Taxonomy_v2021.csv', 'sample_submission.csv', 'test_soundscapes', 'train_audio', 'train_metadata.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(DATASET_BASE_FILE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abethr1', 'abhori1', 'abythr1', 'afbfly1', 'afdfly1', 'afecuc1', 'affeag1', 'afgfly1', 'afghor1', 'afmdov1', 'afpfly1', 'afpkin1', 'afpwag1', 'afrgos1', 'afrgrp1', 'afrjac1', 'afrthr1', 'amesun2', 'augbuz1', 'bagwea1', 'barswa', 'bawhor2', 'bawman1', 'bcbeat1', 'beasun2', 'bkctch1', 'bkfruw1', 'blacra1', 'blacuc1', 'blakit1', 'blaplo1', 'blbpuf2', 'blcapa2', 'blfbus1', 'blhgon1', 'blhher1', 'blksaw1', 'blnmou1', 'blnwea1', 'bltapa1', 'bltbar1', 'bltori1', 'blwlap1', 'brcale1', 'brcsta1', 'brctch1', 'brcwea1', 'brican1', 'brobab1', 'broman1', 'brosun1', 'brrwhe3', 'brtcha1', 'brubru1', 'brwwar1', 'bswdov1', 'btweye2', 'bubwar2', 'butapa1', 'cabgre1', 'carcha1', 'carwoo1', 'categr', 'ccbeat1', 'chespa1', 'chewea1', 'chibat1', 'chtapa3', 'chucis1', 'cibwar1', 'cohmar1', 'colsun2', 'combul2', 'combuz1', 'comsan', 'crefra2', 'crheag1', 'crohor1', 'darbar1', 'darter3', 'didcuc1', 'dotbar1', 'dutdov1', 'easmog1', 'eaywag1', 'edcsun3', 'egygoo', 'equaka1', 'eswdov1', 'eubeat1', 'fatrav1', 'fatwid1', 'fislov1', 'fotdro5', 'gabgos2', 'gargan', 'gbesta1', 'gnbcam2', 'gnhsun1', 'gobbun1', 'gobsta5', 'gobwea1', 'golher1', 'grbcam1', 'grccra1', 'grecor', 'greegr', 'grewoo2', 'grwpyt1', 'gryapa1', 'grywrw1', 'gybfis1', 'gycwar3', 'gyhbus1', 'gyhkin1', 'gyhneg1', 'gyhspa1', 'gytbar1', 'hadibi1', 'hamerk1', 'hartur1', 'helgui', 'hipbab1', 'hoopoe', 'huncis1', 'hunsun2', 'joygre1', 'kerspa2', 'klacuc1', 'kvbsun1', 'laudov1', 'lawgol', 'lesmaw1', 'lessts1', 'libeat1', 'litegr', 'litswi1', 'litwea1', 'loceag1', 'lotcor1', 'lotlap1', 'luebus1', 'mabeat1', 'macshr1', 'malkin1', 'marsto1', 'marsun2', 'mcptit1', 'meypar1', 'moccha1', 'mouwag1', 'ndcsun2', 'nobfly1', 'norbro1', 'norcro1', 'norfis1', 'norpuf1', 'nubwoo1', 'pabspa1', 'palfly2', 'palpri1', 'piecro1', 'piekin1', 'pitwhy', 'purgre2', 'pygbat1', 'quailf1', 'ratcis1', 'raybar1', 'rbsrob1', 'rebfir2', 'rebhor1', 'reboxp1', 'reccor', 'reccuc1', 'reedov1', 'refbar2', 'refcro1', 'reftin1', 'refwar2', 'rehblu1', 'rehwea1', 'reisee2', 'rerswa1', 'rewsta1', 'rindov', 'rocmar2', 'rostur1', 'ruegls1', 'rufcha2', 'sacibi2', 'sccsun2', 'scrcha1', 'scthon1', 'shesta1', 'sichor1', 'sincis1', 'slbgre1', 'slcbou1', 'sltnig1', 'sobfly1', 'somgre1', 'somtit4', 'soucit1', 'soufis1', 'spemou2', 'spepig1', 'spewea1', 'spfbar1', 'spfwea1', 'spmthr1', 'spwlap1', 'squher1', 'strher', 'strsee1', 'stusta1', 'subbus1', 'supsta1', 'tacsun1', 'tafpri1', 'tamdov1', 'thrnig1', 'trobou1', 'varsun2', 'vibsta2', 'vilwea1', 'vimwea1', 'walsta1', 'wbgbir1', 'wbrcha2', 'wbswea1', 'wfbeat1', 'whbcan1', 'whbcou1', 'whbcro2', 'whbtit5', 'whbwea1', 'whbwhe3', 'whcpri2', 'whctur2', 'wheslf1', 'whhsaw1', 'whihel1', 'whrshr1', 'witswa1', 'wlwwar', 'wookin1', 'woosan', 'wtbeat1', 'yebapa1', 'yebbar1', 'yebduc1', 'yebere1', 'yebgre1', 'yebsto1', 'yeccan1', 'yefcan', 'yelbis1', 'yenspu1', 'yertin1', 'yesbar1', 'yespet1', 'yetgre1', 'yewgre1']\n",
      "Number of test samples: 264\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(DATASET_BASE_FILE_PATH + TRAIN_SET_FILE_DIR))\n",
    "print(f\"Number of test samples: {len(os.listdir(DATASET_BASE_FILE_PATH + TRAIN_SET_FILE_DIR))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soundscape_29201.ogg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.listdir(DATASET_BASE_FILE_PATH + TEST_SET_FILE_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of .csv files in base dir\n",
    "- sample_submission.csv\n",
    "- eBird_Taxonomy_v2021.csv\n",
    "- train_metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TAXON_ORDER', 'CATEGORY', 'SPECIES_CODE', 'PRIMARY_COM_NAME', 'SCI_NAME', 'ORDER1', 'FAMILY', 'SPECIES_GROUP', 'REPORT_AS']\n",
      "[dtype('int64'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('O')]\n",
      "Shape of dataframe (rows, columns): (16753, 9)\n",
      "TAXON_ORDER         0.000000\n",
      "CATEGORY            0.000000\n",
      "SPECIES_CODE        0.000000\n",
      "PRIMARY_COM_NAME    0.000000\n",
      "SCI_NAME            0.000000\n",
      "ORDER1              0.000119\n",
      "FAMILY              0.000776\n",
      "SPECIES_GROUP       0.987107\n",
      "REPORT_AS           0.768638\n",
      "dtype: float64\n",
      "TAXON_ORDER         16753\n",
      "CATEGORY                8\n",
      "SPECIES_CODE        16753\n",
      "PRIMARY_COM_NAME    16753\n",
      "SCI_NAME            16753\n",
      "ORDER1                 41\n",
      "FAMILY                249\n",
      "SPECIES_GROUP         216\n",
      "REPORT_AS            1400\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's start with the taxonomy csv file\n",
    "taxonomy = pd.read_csv(DATASET_BASE_FILE_PATH + \"\\\\eBird_Taxonomy_v2021.csv\")\n",
    "\n",
    "print(list(taxonomy.columns))\n",
    "print(list(taxonomy.dtypes))\n",
    "\n",
    "print(f\"Shape of dataframe (rows, columns): {taxonomy.shape}\")\n",
    "\n",
    "# percentage of NANs in each column\n",
    "print(taxonomy.isnull().sum(axis = 0)/taxonomy.shape[0])\n",
    "\n",
    "# Unique values per column\n",
    "print(taxonomy.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TAXON_ORDER CATEGORY SPECIES_CODE       PRIMARY_COM_NAME  \\\n",
      "0            1  species      ostric2         Common Ostrich   \n",
      "1            6  species      ostric3         Somali Ostrich   \n",
      "2            7    slash       y00934  Common/Somali Ostrich   \n",
      "\n",
      "                         SCI_NAME            ORDER1  \\\n",
      "0                Struthio camelus  Struthioniformes   \n",
      "1          Struthio molybdophanes  Struthioniformes   \n",
      "2  Struthio camelus/molybdophanes  Struthioniformes   \n",
      "\n",
      "                      FAMILY SPECIES_GROUP REPORT_AS  \n",
      "0  Struthionidae (Ostriches)     Ostriches       NaN  \n",
      "1  Struthionidae (Ostriches)           NaN       NaN  \n",
      "2  Struthionidae (Ostriches)           NaN       NaN  \n",
      "       TAXON_ORDER CATEGORY SPECIES_CODE                     PRIMARY_COM_NAME  \\\n",
      "12036        24431     issf      marwhi1           Lesser Whitethroat (Gansu)   \n",
      "8744         16668     issf      bncfly5  Brown-crested Flycatcher (Cooper's)   \n",
      "7684         14502  species       swfgle         Slaty-winged Foliage-gleaner   \n",
      "\n",
      "                                   SCI_NAME         ORDER1  \\\n",
      "12036           Curruca curruca margelanica  Passeriformes   \n",
      "8744   Myiarchus tyrannulus [cooperi Group]  Passeriformes   \n",
      "7684                    Philydor fuscipenne  Passeriformes   \n",
      "\n",
      "                                                  FAMILY SPECIES_GROUP  \\\n",
      "12036  Sylviidae (Sylviid Warblers, Parrotbills, and ...           NaN   \n",
      "8744                     Tyrannidae (Tyrant Flycatchers)           NaN   \n",
      "7684            Furnariidae (Ovenbirds and Woodcreepers)           NaN   \n",
      "\n",
      "      REPORT_AS  \n",
      "12036   leswhi4  \n",
      "8744     bncfly  \n",
      "7684        NaN  \n"
     ]
    }
   ],
   "source": [
    "print(taxonomy.head(3))\n",
    "print(taxonomy.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['form', 'issf', 'spuh', 'species', 'hybrid', 'slash', 'intergrade', 'domestic']\n"
     ]
    }
   ],
   "source": [
    "# closer look into category column\n",
    "print(list(set(taxonomy['CATEGORY'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of taxonomy csv\n",
    "- 9 columns, ca. 17k rows\n",
    "- Littel non-NAN entires in SPECIES_GROUP and REPORT_AS\n",
    "- SPECIES_CODE could be used to get more infomration from https://ebird.org/species/SPECIES_CODE\n",
    "- Everything else is a black box for me currently\n",
    "\n",
    "#### Open questions\n",
    "- What exactly is the TAXON_ORDER?\n",
    "- What are the categories in the CATEGORY column besides species?\n",
    "- How to use this taxonomy information?\n",
    "    - To combine / seperate data of species living close to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['primary_label', 'secondary_labels', 'type', 'latitude', 'longitude', 'scientific_name', 'common_name', 'author', 'license', 'rating', 'url', 'filename']\n",
      "[dtype('O'), dtype('O'), dtype('O'), dtype('float64'), dtype('float64'), dtype('O'), dtype('O'), dtype('O'), dtype('O'), dtype('float64'), dtype('O'), dtype('O')]\n",
      "Shape of dataframe (rows, columns): (16941, 12)\n",
      "primary_label       0.000000\n",
      "secondary_labels    0.000000\n",
      "type                0.000000\n",
      "latitude            0.013399\n",
      "longitude           0.013399\n",
      "scientific_name     0.000000\n",
      "common_name         0.000000\n",
      "author              0.000000\n",
      "license             0.000000\n",
      "rating              0.000000\n",
      "url                 0.000000\n",
      "filename            0.000000\n",
      "dtype: float64\n",
      "primary_label         264\n",
      "secondary_labels      751\n",
      "type                  796\n",
      "latitude             6252\n",
      "longitude            6301\n",
      "scientific_name       264\n",
      "common_name           264\n",
      "author               1082\n",
      "license                 4\n",
      "rating                 11\n",
      "url                 16941\n",
      "filename            16941\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analysis of train metadata csv\n",
    "train_metadata = pd.read_csv(DATASET_BASE_FILE_PATH + \"\\\\train_metadata.csv\")\n",
    "\n",
    "print(list(train_metadata.columns))\n",
    "print(list(train_metadata.dtypes))\n",
    "\n",
    "print(f\"Shape of dataframe (rows, columns): {train_metadata.shape}\")\n",
    "\n",
    "# percentage of NANs in each column\n",
    "print(train_metadata.isnull().sum(axis = 0)/train_metadata.shape[0])\n",
    "\n",
    "# Unique values per column\n",
    "print(train_metadata.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  primary_label secondary_labels      type  latitude  longitude  \\\n",
      "0       abethr1               []  ['song']    4.3906    38.2788   \n",
      "1       abethr1               []  ['call']   -2.9524    38.2921   \n",
      "2       abethr1               []  ['song']   -2.9524    38.2921   \n",
      "\n",
      "      scientific_name               common_name         author  \\\n",
      "0  Turdus tephronotus  African Bare-eyed Thrush  Rolf A. de By   \n",
      "1  Turdus tephronotus  African Bare-eyed Thrush  James Bradley   \n",
      "2  Turdus tephronotus  African Bare-eyed Thrush  James Bradley   \n",
      "\n",
      "                                             license  rating  \\\n",
      "0  Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
      "1  Creative Commons Attribution-NonCommercial-Sha...     3.5   \n",
      "2  Creative Commons Attribution-NonCommercial-Sha...     3.5   \n",
      "\n",
      "                                 url              filename  \n",
      "0  https://www.xeno-canto.org/128013  abethr1/XC128013.ogg  \n",
      "1  https://www.xeno-canto.org/363501  abethr1/XC363501.ogg  \n",
      "2  https://www.xeno-canto.org/363502  abethr1/XC363502.ogg  \n",
      "      primary_label secondary_labels              type  latitude  longitude  \\\n",
      "14495       varsun2               []          ['call']   -6.9187    36.5722   \n",
      "6304         egygoo               []          ['call']   51.4049    -0.5220   \n",
      "8974         hoopoe               []  ['male', 'song']   37.5672    -6.0486   \n",
      "\n",
      "            scientific_name       common_name                 author  \\\n",
      "14495     Cinnyris venustus  Variable Sunbird        Louis A. Hansen   \n",
      "6304   Alopochen aegyptiaca    Egyptian Goose  David Darrell-Lambert   \n",
      "8974            Upupa epops   Eurasian Hoopoe      José Carlos Sires   \n",
      "\n",
      "                                                 license  rating  \\\n",
      "14495  Creative Commons Attribution-NonCommercial-Sha...     2.0   \n",
      "6304   Creative Commons Attribution-NonCommercial-Sha...     4.0   \n",
      "8974   Creative Commons Attribution-NonCommercial-Sha...     2.0   \n",
      "\n",
      "                                     url              filename  \n",
      "14495  https://www.xeno-canto.org/515279  varsun2/XC515279.ogg  \n",
      "6304   https://www.xeno-canto.org/305663   egygoo/XC305663.ogg  \n",
      "8974   https://www.xeno-canto.org/306289   hoopoe/XC306289.ogg  \n"
     ]
    }
   ],
   "source": [
    "print(train_metadata.head(3))\n",
    "print(train_metadata.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate results\n",
    "- 16941 rows, 12 columns\n",
    "- Little NAN entries accross all columns\n",
    "\n",
    "#### Open questions\n",
    "- How to use the extra information?\n",
    "    - As far as I understood it we do NOT have such metadata in the inference case\n",
    "- Scientific name the same as in the taxonomy file? --> We could join on this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of train set files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 126, 28, 18, 31, 90, 48, 8, 72, 37, 104, 1, 81, 57, 25, 30, 45, 43, 12, 24, 500, 47, 7, 81, 34, 109, 28, 60, 76, 262, 50, 166, 22, 38, 23, 16, 13, 26, 17, 11, 7, 20, 15, 10, 3, 62, 2, 29, 22, 38, 30, 8, 1, 81, 40, 27, 67, 9, 30, 34, 153, 43, 166, 13, 6, 8, 79, 27, 29, 113, 425, 181, 293, 477, 500, 1, 36, 49, 32, 7, 79, 3, 8, 15, 500, 21, 152, 7, 63, 437, 25, 5, 15, 137, 34, 136, 45, 239, 19, 81, 3, 5, 2, 94, 12, 138, 252, 103, 26, 28, 20, 10, 51, 72, 53, 24, 46, 9, 129, 30, 18, 59, 8, 436, 16, 5, 7, 34, 56, 9, 109, 68, 14, 40, 29, 378, 72, 18, 15, 1, 3, 19, 16, 6, 15, 6, 40, 8, 32, 36, 30, 24, 16, 20, 21, 20, 20, 22, 7, 14, 4, 91, 121, 52, 10, 14, 44, 172, 17, 281, 47, 28, 21, 56, 122, 70, 12, 42, 59, 9, 2, 5, 25, 227, 28, 116, 22, 10, 33, 6, 6, 78, 30, 25, 3, 45, 68, 23, 51, 33, 21, 199, 22, 21, 42, 41, 37, 32, 13, 12, 94, 59, 48, 119, 33, 4, 90, 37, 6, 161, 97, 500, 98, 105, 19, 88, 18, 34, 27, 132, 78, 48, 10, 73, 7, 23, 19, 34, 9, 1, 17, 1, 14, 8, 5, 500, 67, 486, 28, 106, 34, 17, 35, 22, 1, 13, 75, 19, 12, 134, 29, 15, 27, 108]\n",
      "Max. samples: 1,     Min. samples: 500,     Mean samples: 64.17045454545455\n"
     ]
    }
   ],
   "source": [
    "list_of_dirs_in_train_dir = os.listdir(DATASET_BASE_FILE_PATH + TRAIN_SET_FILE_DIR)\n",
    "number_of_files_for_single_sample = []\n",
    "\n",
    "for single_dir in list_of_dirs_in_train_dir:\n",
    "    number_of_files = len(os.listdir(DATASET_BASE_FILE_PATH + TRAIN_SET_FILE_DIR + \"\\\\\" + single_dir))\n",
    "    number_of_files_for_single_sample.append(number_of_files)\n",
    "\n",
    "print(number_of_files_for_single_sample)\n",
    "print(\n",
    "    f\"Max. samples: {min(number_of_files_for_single_sample)}, \\\n",
    "    Min. samples: {max(number_of_files_for_single_sample)}, \\\n",
    "    Mean samples: {sum(number_of_files_for_single_sample)/len(number_of_files_for_single_sample)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution per training samples to get a feeling for the balance of the training set\n",
    "plt.bar(list_of_dirs_in_train_dir, number_of_files_for_single_sample)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bars after sorting and the cummulative sum in one plot\n",
    "number_of_files_for_single_sample_sorted, list_of_dirs_in_train_dir_sorted = map(list, zip(*sorted(zip(number_of_files_for_single_sample, list_of_dirs_in_train_dir), reverse=True)))\n",
    "\n",
    "cum_sum_samples = np.cumsum(number_of_files_for_single_sample_sorted)\n",
    "total_file_sum = sum(number_of_files_for_single_sample_sorted)\n",
    "cum_sum_samples = np.divide(cum_sum_samples, np.repeat(total_file_sum, len(cum_sum_samples)))\n",
    "\n",
    "fig, ax1 = plt.subplots() \n",
    "ax1.set_xlabel('Train samples') \n",
    "ax1.set_ylabel('Cumulative sum', color = 'red') \n",
    "ax1.plot(list_of_dirs_in_train_dir_sorted, cum_sum_samples, color = 'red') \n",
    "ax1.tick_params(axis ='y', labelcolor = 'red') \n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Samples', color = 'blue') \n",
    "ax2.bar(list_of_dirs_in_train_dir_sorted, number_of_files_for_single_sample_sorted, color = 'blue') \n",
    "ax2.tick_params(axis ='y', labelcolor = 'blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate results\n",
    "\n",
    "- Training dataset is skewed\n",
    "    - Long tail of training classes with less than 10 examples. Even a few training classes with only <b>one</b> samples\n",
    "    - Maximum samples of training classes is 500\n",
    "- <b>Need to account for skewness</b>\n",
    "    - Important for training/validation split --> stratification needed if data is used as is\n",
    "    - Downsampling might not be a good idea as we throw away up to 499 samples of some classes\n",
    "    - How do we upsample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
